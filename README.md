# Tech Challenge Book API
Plataforma FastAPI criada para o Tech Challenge, focada em expor e enriquecer um cat√°logo de livros obtido via web scraping do site `books.toscrape.com`. O projeto combina coleta automatizada, pipelines de dados, autentica√ß√£o JWT e rotas especializadas para an√°lises e prepara√ß√£o de dados para Machine Learning.

## Links R√°pidos
- **Link do Deploy**: [https://book-api-mlet.onrender.com](https://book-api-mlet.onrender.com/)
- **V√≠deo de Demonstra√ß√£o**: *TODO*
- **Documenta√ß√£o Completa (Wiki)**
  - [Home da Wiki](https://github.com/andrevberaldo/tech-challenge-book-api/wiki/Tech-Challenge-Book-API)
  - [Vis√£o Geral e Arquitetura](https://github.com/andrevberaldo/tech-challenge-book-api/wiki/Vis%C3%A3o-Geral-e-Arquitetura)
  - [Instala√ß√£o e Configura√ß√£o](https://github.com/andrevberaldo/tech-challenge-book-api/wiki/Instala%C3%A7%C3%A3o-e-Configura%C3%A7%C3%A3o)
  - [Documenta√ß√£o das Rotas](https://github.com/andrevberaldo/tech-challenge-book-api/wiki/Documenta%C3%A7%C3%A3o-das-Rotas)
  - [Exemplos de Chamadas HTTP](https://github.com/andrevberaldo/tech-challenge-book-api/wiki/Exemplos-de-Chamadas-HTTP)
  - [Opera√ß√£o e Execu√ß√£o](https://github.com/andrevberaldo/tech-challenge-book-api/wiki/Opera%C3%A7%C3%A3o-e-Execu%C3%A7%C3%A3o)

> A Wiki acompanha este README e aprofunda todos os t√≥picos: arquitetura, fluxo de dados, automa√ß√µes, exemplos de requisi√ß√µes e checklists operacionais.

## Objetivos do Projeto
- Disponibilizar endpoints p√∫blicos para consulta do cat√°logo de livros j√° processado.
- Expor rotas privadas (com JWT) para estat√≠sticas avan√ßadas, datasets de ML e automa√ß√µes (scrapper/pipeline).
- Demonstrar boas pr√°ticas de engenharia de dados: coleta, limpeza, feature engineering e consumo via API.
- Facilitar deploy local e containerizado, com suporte opcional a PostgreSQL para persist√™ncia de usu√°rios e tokens.

## Principais Recursos
- **Rotas p√∫blicas**: listagem, busca e detalhamento de livros (`/api/v1/books`, `/api/v1/categories`, etc.).
- **Rotas privadas**: estat√≠sticas, datasets de ML, disparo da pipeline e scrapper, acesso a diagramas HTML.
- **Autentica√ß√£o JWT**: emiss√£o e renova√ß√£o de tokens (`/api/v1/auth/login` e `/api/v1/auth/refresh`).
- **Pipeline de dados**: limpeza, valida√ß√£o, gera√ß√£o de features e invalida√ß√£o autom√°tica de caches.
- **Scrapper resiliente**: `requests` + `BeautifulSoup` com backoff, salvando CSV bruto em `src/data/raw`.
- **Observabilidade pronta**: depend√™ncias de OpenTelemetry j√° configuradas para instrumenta√ß√£o opcional.

## Arquitetura em Alto N√≠vel
```
src/
‚îú‚îÄ app.py                 # Configura FastAPI e registra routers
‚îú‚îÄ routes/                # Endpoints p√∫blicos e privados
‚îú‚îÄ domain/                # Regras de neg√≥cio, servi√ßos e reposit√≥rios
‚îú‚îÄ scripts/               # Pipelines, scrapper e utilit√°rios de ML
‚îú‚îÄ data/                  # Artefatos raw, processed e features
‚îú‚îÄ docs/                  # Diagramas (HTML) servidos pelas rotas privadas
‚îî‚îÄ templates/             # Landing page p√∫blica
```

Fluxo de dados:
```
Scrapper ‚Üí src/data/raw/all_books_with_images.csv
Pipeline (limpeza + features) ‚Üí processed/books_processed.csv ‚Üí features/books_features.csv
Rotas ‚Üí servem os CSVs com cache e convers√µes em tempo real
```

### Diagrama de Arquitetura (Mermaid)
```mermaid
flowchart LR
   subgraph Scraper
      S((Scrapper))
   end
   subgraph Pipelines
      P1[Limpeza de Dados]
      P2[Feature Engineering]
   end
   subgraph Storage
      RAW[(CSV Raw)]
      PROC[(CSV Processado)]
      FEAT[(CSV Features)]
      DB[(PostgreSQL opcional)]
   end
   subgraph API
      A1[/Rotas P√∫blicas/]
      A2[/Rotas Privadas/]
      A3[/Autentica√ß√£o/]
   end
   subgraph Clients
      C1[Swagger]
      C2[Aplica√ß√µes externas]
      C3[Data Science]
   end

   S --> RAW
   RAW --> P1 --> PROC
   PROC --> P2 --> FEAT
   A1 --> PROC
   A2 --> FEAT
   A3 --> DB
   A2 --> DB
   DB -. opcional .- PROC
   A1 --> C1
   A2 --> C2
   FEAT --> C3
```

## Como Reproduzir em Ambiente Local (sem Docker)
1. Crie e ative o ambiente virtual:
  ```bash
  python -m venv .venv
  # Linux/macOS
  source .venv/bin/activate
  # Windows PowerShell
  .\.venv\Scripts\Activate.ps1
  ```
2. Instale as depend√™ncias:
  ```bash
  pip install -r requirements.txt
  ```
3. Crie o `.env` na raiz:
  ```ini
  JWT_SECRET=secret_here
  USE_DATABASE=False
  ```
4. Inicie a API:
  - Linux/macOS: `./devops/start_local.sh`
  - Windows PowerShell: `./devops/start_local.ps1`

A aplica√ß√£o ficar√° dispon√≠vel em `http://localhost:4000` com documenta√ß√£o Swagger em `http://localhost:4000/docs`.

## Execu√ß√£o com Docker Compose
1. Ajuste o `.env` com as credenciais necess√°rias:
  ```ini
  JWT_SECRET=secret_here
  USE_DATABASE=False
  DB_HOST=postgres
  DB_USER=admin
  DB_PASSWORD=admin
  ```
2. Suba os servi√ßos:
  ```bash
  docker compose up --build
  ```
3. Servi√ßos expostos:
  - API: `http://localhost:4000`
  - PostgreSQL: `localhost:5432`
  - pgAdmin4: `http://localhost:5050` (login `admin@admin.com` / senha `admin`)

Para provisionar usu√°rios/tokens no banco, execute `init/01-schema.sql` e `init/02-seed.sql` dentro do container Postgres.

## Vari√°veis de Ambiente
| Nome | Obrigat√≥rio | Padr√£o | Descri√ß√£o |
|------|-------------|--------|-----------|
| `JWT_SECRET` | Sim | ‚Äî | Chave usada para assinar e validar JWT. |
| `USE_DATABASE` | N√£o | `False` | Quando `True`, utiliza PostgreSQL em vez de reposit√≥rios em mem√≥ria. |
| `BOOKS_CSV_PATH` | N√£o | `src/data/raw/all_books_with_images.csv` | Fonte bruta usada no health-check. |
| `BOOKS_PROCESSED_PATH` | N√£o | `src/data/processed/books_processed.csv` | Dataset servido pelas rotas p√∫blicas. |
| `BOOK_SCRAPER_OUTPUT` | N√£o | `src/data/raw` | Diret√≥rio de sa√≠da do scrapper. |
| `GIT_HASH` | N√£o | `unknown-version` | Hash exibido em `/api/v1/version`. |
| `DB_HOST` | Quando `USE_DATABASE=True` | ‚Äî | Host do PostgreSQL. |
| `DB_PORT` | N√£o | `5432` | Porta do PostgreSQL. |
| `DB_USER` | Quando `USE_DATABASE=True` | ‚Äî | Usu√°rio do PostgreSQL. |
| `DB_PASSWORD` | Quando `USE_DATABASE=True` | ‚Äî | Senha do PostgreSQL. |
| `DB_NAME` | N√£o | `book-api` | Nome do banco. |
| `DB_SSLMODE` | N√£o | `prefer` | Modo SSL para psycopg (health-check). |
| `DB_CONNECT_TIMEOUT` | N√£o | `3` | Timeout (s) para psycopg. |
| `DB_TCP_TIMEOUT` | N√£o | `2.5` | Timeout (s) para fallback TCP. |

## Autentica√ß√£o e Autoriza√ß√£o
1. `GET /api/v1/auth/login` ‚Äî exige `Authorization: Basic`, retorna `accessToken` (curta dura√ß√£o) e `refreshToken`.
2. `GET /api/v1/auth/refresh` ‚Äî recebe `Authorization: Bearer <refreshToken>` e devolve novo `accessToken`.
3. Rotas privadas (`/api/v1/stats/*`, `/api/v1/ml/*`, `/api/v1/data-process`, `/api/v1/scrapper`, `/api/v1/diagrams/*`) validam o access token via `JWTUtils.validate_token`.
4. Com `USE_DATABASE=True`, os reposit√≥rios `DBAuthRepository` e `DBUserRepository` passam a persistir tokens e usu√°rios no PostgreSQL; caso contr√°rio, s√£o usados reposit√≥rios em mem√≥ria.

## Endpoints Principais
| M√©todo | Rota | Descri√ß√£o | Autentica√ß√£o |
|--------|------|-----------|--------------|
| GET | `/` | Landing page com integrantes e link da doc. | P√∫blica |
| GET | `/api/v1/health` | Health-check do CSV e banco (quando configurado). | P√∫blica |
| GET | `/api/v1/books` | Lista completa de livros processados. | P√∫blica |
| GET | `/api/v1/books/search` | Busca por t√≠tulo e/ou categoria. | P√∫blica |
| GET | `/api/v1/books/{id}` | Detalhes de um livro por ID. | P√∫blica |
| GET | `/api/v1/categories` | Lista de categorias dispon√≠veis. | P√∫blica |
| GET | `/api/v1/auth/login` | Emite access/refresh tokens via Basic Auth. | Basic |
| GET | `/api/v1/stats/overview` | Estat√≠sticas gerais do cat√°logo. | Bearer |
| GET | `/api/v1/ml/features` | Dataset de features para ML. | Bearer |
| GET | `/api/v1/diagrams/*` | Diagramas HTML do projeto. | Bearer |
| PUT | `/api/v1/data-process` | Dispara pipeline de processamento de dados. | Bearer |
| PUT | `/api/v1/scrapper` | Inicia scraping em background. | Bearer |

Consulte a [Documenta√ß√£o das Rotas](https://github.com/andrevberaldo/tech-challenge-book-api/wiki/Documenta%C3%A7%C3%A3o-das-Rotas) para par√¢metros, payloads e respostas detalhadas.

## Pipeline de Dados e Scrapper
- **Scrapper**: disparo via `PUT /api/v1/scrapper` ou execu√ß√£o direta `python -c "from src.scripts.scrapper_lib import trigger_scrap; trigger_scrap()"`.
- **Pipeline completa**: `PUT /api/v1/data-process` ou `python -m src.scripts.data_processing_pipeline`.
- **Artefatos gerados**: diret√≥rios `src/data/raw/`, `src/data/processed/`, `src/data/features/`.
- **Cache inteligente**: endpoints invalidam caches automaticamente com base no `mtime` dos arquivos.

## Testes e Qualidade
```bash
pytest
```
- `tests/unit_tests/`: cobre pipelines, estat√≠sticas e rotas cr√≠ticas.
- `tests/smoke_tests/`: verifica√ß√£o r√°pida p√≥s-deploy.
- `tests/run_tests.py`: entry point auxiliar para execu√ß√£o dos testes.

## Estrutura de Pastas (resumo)
```
devops/            Scripts de bootstrap (Linux/Windows)
init/              DDL e seeds do PostgreSQL
notebooks/         An√°lises explorat√≥rias e estudos pr√©vios
src/               C√≥digo-fonte da API, dom√≠nio e pipelines
tests/             Suite de testes unit√°rios e smoke
wiki/              Conte√∫do pronto para a aba Wiki do GitHub
```

## üôå Contribui√ß√£o
- Abra issues ou pull requests descrevendo claramente a altera√ß√£o proposta.
- Garanta que os testes relevantes estejam passando (`pytest`).
- Atualize a Wiki sempre que novos fluxos ou diagramas forem adicionados.

---
Projeto mantido por `andrevberaldo` e colaboradores do Tech Challenge.

